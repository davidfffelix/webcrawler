# ğŸ•·ï¸ WebCrawler de Proxies

Este projeto Ã© um **WebCrawler multithread em C# e .NET** desenvolvido como desafio tÃ©cnico. Ele acessa o site [proxyservers.pro](https://proxyservers.pro/proxy/list/order/updated/order_dir/desc), extrai informaÃ§Ãµes de proxies de vÃ¡rias pÃ¡ginas e salva os dados em um arquivo JSON, alÃ©m de registrar logs da execuÃ§Ã£o em um banco de dados SQLite.

---

## âœ… Funcionalidades

- âœ… Extrai os campos:
  - IP Address
  - Port
  - Country
  - Protocol
- âœ… Salva os dados extraÃ­dos em um arquivo `proxies.json`.
- âœ… Gera arquivos `.html` de cada pÃ¡gina acessada (para auditoria).
- âœ… Registra em banco de dados SQLite:
  - Data de inÃ­cio da execuÃ§Ã£o
  - Data de tÃ©rmino da execuÃ§Ã£o
  - Quantidade de pÃ¡ginas processadas
  - Quantidade de proxies (linhas) extraÃ­das em todas as pÃ¡ginas
  - Caminho do arquivo JSON gerado
- âœ… ExecuÃ§Ã£o multithread com atÃ© 3 tarefas simultÃ¢neas (controle de concorrÃªncia com `SemaphoreSlim`)

---

## ğŸ§± Estrutura do Projeto

```
WebCrawler/
â”‚
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ Proxy.cs
â”‚   â””â”€â”€ CrawlerLog.cs
â”‚
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ ProxyService.cs
â”‚   â”œâ”€â”€ IProxyService.cs
â”‚   â”œâ”€â”€ DatabaseService.cs
â”‚   â””â”€â”€ HtmlHelper.cs
â”‚
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ ProxyCrawler.db (gerado automaticamente)
â”‚
â”œâ”€â”€ pagina_1.html ... pagina_n.html (gerados na execuÃ§Ã£o)
â”‚
â”œâ”€â”€ proxies.json (resultado final)
â”‚
â””â”€â”€ Program.cs (ponto de entrada)
```

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **C# com .NET 6+** â€” linguagem principal e ambiente de execuÃ§Ã£o.
- **HttpClient** â€” usado para realizar as requisiÃ§Ãµes HTTP ao site de proxies.
- **HtmlAgilityPack** â€” biblioteca para parse e extraÃ§Ã£o de dados HTML de forma robusta.
- **System.Text.Json** â€” utilizado para serializar os dados extraÃ­dos para o arquivo `proxies.json`.
- **SQLite** com `Microsoft.Data.Sqlite` â€” banco de dados leve para armazenar logs de execuÃ§Ã£o localmente.
- **Multithreading** com `Task` e `SemaphoreSlim` â€” permite que atÃ© 3 tarefas simultÃ¢neas sejam executadas, otimizando a performance do crawler.

---

## ğŸ“¦ Como Executar

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/seuusuario/WebCrawler.git
cd WebCrawler
```

2. Restaure os pacotes e compile o projeto:

```bash
dotnet restore
dotnet build
```

3. Execute o projeto:

```bash
dotnet run
```

> O processo pode levar alguns segundos dependendo da conexÃ£o. Verifique os arquivos gerados apÃ³s a execuÃ§Ã£o:
> - `proxies.json`
> - `pagina_1.html`, `pagina_2.html`, ...
> - `Data/ProxyCrawler.db`

---

## ğŸ“¸ Exemplo de Resultado

```json
[
  {
    "IPAddress": "123.456.789.000",
    "Port": "8080",
    "Country": "Brazil",
    "Protocol": "HTTP"
  },
  ...
]
```

---

## ğŸ“š LicenÃ§a

Este projeto Ã© apenas para fins de avaliaÃ§Ã£o tÃ©cnica.
